import React, { useEffect, useState, useRef } from "react";
import {
  View,
  Text,
  TouchableOpacity,
  StyleSheet,
  Platform,
  PermissionsAndroid,
} from "react-native";
import AudioRecorderPlayer from "react-native-audio-recorder-player";
import io from "socket.io-client";
import RNFS from "react-native-fs";

const SERVER_URL = "http://127.0.0.1:8000/"; // ë°±ì—”ë“œ ì„œë²„ ì£¼ì†Œ
const audioRecorderPlayer = new AudioRecorderPlayer();
const socket = useRef(null); // âœ… WebSocket useRef ì‚¬ìš©

const VoicePage = () => {
  const [transcription, setTranscription] = useState(""); // ë³€í™˜ëœ í…ìŠ¤íŠ¸
  const [isRecording, setIsRecording] = useState(false);
  const [loading, setLoading] = useState(true);
  const [capturedImage, setCapturedImage] = useState(null);

  useEffect(() => {
    requestPermissions(); // âœ… ì•± ì‹¤í–‰ ì‹œ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
  }, []);

  useEffect(() => {
    fetch(`http://127.0.0.1:8000/api/video_play?video_id=1`)
      .then((response) => response.json())
      .then(() => setLoading(false))
      .catch((error) => {
        console.error("API ìš”ì²­ ì‹¤íŒ¨:", error);
        setLoading(false);
      });
  }, []);

  useEffect(() => {
    // âœ… WebSocket ì—°ê²°
    socket.current = io(SERVER_URL, { transports: ["websocket"] });

    socket.current.on("connect", () => {
      console.log("âœ… WebSocket Connected!");
    });

    startRecording(); // ë…¹ìŒ ì‹œì‘

    socket.current.on("disconnect", () => {
      console.log("âŒ WebSocket Disconnected!");
    });

    socket.current.on("error", (error) => {
      console.error("âŒ WebSocket Error:", error);
    });

    socket.current.on("wake_word_detected", () => {
      console.log("âœ… 'ìƒˆë¯¸ì•¼' ê°ì§€ë¨! ë¹„ë””ì˜¤ ìº¡ì²˜ ì‹œì‘");
      try {
        handleCapture();
      } catch (error) {
        console.error("âŒ handleCapture ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:", error);
      }
    });

    socket.current.on("result_data", (data) => {
      console.log("ğŸ“¦ ì„œë²„ ì‘ë‹µ:", data);
      setTranscription(data.text);
    });

    return () => {
      if (socket.current) {
        socket.current.disconnect();
        console.log("âŒ WebSocket Disconnected");
      }
    };
  }, []);

  const requestPermissions = async () => {
    if (Platform.OS === "android") {
      try {
        const granted = await PermissionsAndroid.request(
          PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
          {
            title: "ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­",
            message: "ì´ ì•±ì€ ìŒì„± ë…¹ìŒì„ ìœ„í•´ ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
            buttonNeutral: "ë‚˜ì¤‘ì—",
            buttonNegative: "ì·¨ì†Œ",
            buttonPositive: "í™•ì¸",
          }
        );
        if (granted !== PermissionsAndroid.RESULTS.GRANTED) {
          console.log("âŒ ë§ˆì´í¬ ê¶Œí•œ ê±°ë¶€ë¨");
          return false;
        }
      } catch (error) {
        console.error("âŒ ê¶Œí•œ ìš”ì²­ ì‹¤íŒ¨:", error);
        return false;
      }
    }
    return true;
  };

  const startRecording = async () => {
    try {
      console.log("ğŸ¤ Start Recording...");

      // âœ… ì €ì¥ ê²½ë¡œ: ì•± ë‚´ë¶€ ì €ì¥ì†Œ ì‚¬ìš©
      const filePath =
        Platform.OS === "ios"
          ? `${RNFS.DocumentDirectoryPath}/recording.m4a` // iOS: AAC
          : `${RNFS.DocumentDirectoryPath}/recording.aac`; // Android: AAC

      console.log("ğŸ“ ì €ì¥ ê²½ë¡œ:", filePath);

      const result = await audioRecorderPlayer.startRecorder(filePath, {
        AVFormatIDKeyIOS: "kAudioFormatMPEG4AAC", // âœ… iOSëŠ” AAC ì‚¬ìš©
        AudioEncoderAndroid: "aac", // âœ… Androidë„ AAC ì‚¬ìš©
      });

      console.log("ğŸ¤ Recorder started:", result);

      audioRecorderPlayer.addRecordBackListener((e) => {
        console.log("ğŸ¤ Recording Buffer:", e.recordingBuffer);
        if (socket.current) {
          socket.current.emit("audio_stream", e.recordingBuffer);
        }
      });

      setIsRecording(true);
    } catch (error) {
      console.error("âŒ Recording Error:", error);
    }
  };

  const stopRecording = async () => {
    setIsRecording(false);
    try {
      await audioRecorderPlayer.stopRecorder();
      console.log("â¹ ë…¹ìŒ ì¤‘ì§€ë¨");
    } catch (error) {
      console.error("âŒ ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜:", error);
    }
  };

  return (
    <View style={styles.container}>
      <TouchableOpacity
        style={styles.recordButton}
        onPress={isRecording ? stopRecording : startRecording}
      >
        <Text style={styles.buttonText}>
          {isRecording ? "â¹ ë…¹ìŒ ì¤‘ì§€" : "ğŸ¤ ë…¹ìŒ ì‹œì‘"}
        </Text>
      </TouchableOpacity>

      <Text style={styles.text}>ğŸ“œ ì¸ì‹ëœ ë¬¸ì¥: {transcription}</Text>
    </View>
  );
};

const styles = StyleSheet.create({
  container: { flex: 1, justifyContent: "center", alignItems: "center" },
  recordButton: { backgroundColor: "red", padding: 10, borderRadius: 5 },
  buttonText: { color: "white", fontSize: 18 },
  text: { marginTop: 20, fontSize: 16 },
});

export default VoicePage;
